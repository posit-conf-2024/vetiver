---
title: "3 - Deeper into deployment"
subtitle: "Intro to MLOps with vetiver"
format:
  revealjs: 
    slide-number: true
    footer: <https://posit-conf-2024.github.io/vetiver>
    preview-links: auto
    incremental: true
    theme: [default, styles.scss]
    width: 1280
    height: 720
knitr:
  opts_chunk: 
    echo: true
    collapse: true
    comment: "#>"
---

```{r}
#| include: false
#| file: setup.R
```

## Plan for this workshop

::: nonincremental
-   *Versioning*
    -   Managing change in models ‚úÖ
-   *Deploying*
    -   Putting models in REST APIs üéØ
-   *Monitoring*
    -   Tracking model performance üëÄ
:::

# Where does vetiver work?

::: nonincremental
-   Posit's pro products, like [Connect](https://posit.co/products/enterprise/connect/)

-   AWS SageMaker (R only, for now)

-   A public or private cloud, using Docker
:::


# {background-color="white" background-image="https://1000logos.net/wp-content/uploads/2021/11/Docker-Logo-1536x864.png" background-size="70%"}

# Docker

_Containerized environments for your code_

## Why Docker?

::: nonincremental
-   Open source
-   Reproducible
-   Bring your own container philosophy
:::

::: notes
ECR in AWS, etc
huggingface
:::

## Why Docker?

![](https://external-preview.redd.it/aR6WdUcsrEgld5xUlglgKX_0sC_NlryCPTXIHk5qdu8.jpg?auto=webp&s=5fe64dd318eec71711d87805d43def2765dd83cd){fig-align="center"}

## Create Docker artifacts

Start with a trained and versioned model

. . .

::: nonincremental
-   Dockerfile
-   Model dependencies, typically `requirements.txt` or `renv.lock`
-   File to serve API, typically `app.py` or `plumber.R`
:::


## Create Docker artifacts

Start with a trained and versioned model

### Python

```{python}
#| eval: false
vetiver.prepare_docker(
    board, 
    "isabel.zimmerman/seattle-housing-python"
    port = 8080
)
```

### R

```{r}
#| eval: false
vetiver_prepare_docker(
    board, 
    "julia.silge/seattle-housing-rstats", 
    docker_args = list(port = 8080)
)
```

## Dockerfiles for vetiver

### Python

```docker
# # Generated by the vetiver package; edit with care
# start with python base image
FROM python:3.11

# create directory in container for vetiver files
WORKDIR /vetiver

# copy and install requirements
COPY vetiver_requirements.txt /vetiver/requirements.txt

#
RUN pip install --no-cache-dir --upgrade -r /vetiver/requirements.txt

# copy app file
COPY app.py /vetiver/app/app.py

# expose port
EXPOSE 8080

# run vetiver API
CMD ["uvicorn", "app.app:api", "--host", "0.0.0.0", "--port", "8080"]
```

## Dockerfiles for vetiver

### R

```docker
# Generated by the vetiver package; edit with care

FROM rocker/r-ver:4.4.0
ENV RENV_CONFIG_REPOS_OVERRIDE https://packagemanager.rstudio.com/cran/latest

RUN apt-get update -qq && apt-get install -y --no-install-recommends \
  libcurl4-openssl-dev \
  libicu-dev \
  libsodium-dev \
  libssl-dev \
  make \
  zlib1g-dev \
  && apt-get clean

COPY vetiver_renv.lock renv.lock
RUN Rscript -e "install.packages('renv')"
RUN Rscript -e "renv::restore()"
COPY plumber.R /opt/ml/plumber.R
EXPOSE 8080
ENTRYPOINT ["R", "-e", "pr <- plumber::plumb('/opt/ml/plumber.R'); pr$run(host = '0.0.0.0', port = 8080)"]

```

## Build your container

```bash
docker build -t housing .
```

## Run your container {auto-animate=true}

```bash
docker run -p 8080:8080 housing
```

## Run your container {auto-animate=true}

```bash
docker run --env-file .env -p 8080:8080 housing
```

::: notes
probably .Renv if you are in R
:::

## Make predictions

### R

```{r}
#| eval: false
endpoint <- vetiver_endpoint("http://0.0.0.0:8080/predict")
predict(endpoint, X_test)
```

### Python

```{python}
#| eval: false
endpoint = vetiver.vetiver_endpoint("http://0.0.0.0:8080/predict")
vetiver.predict(endpoint=endpoint, data=X_test)
```

# Demo

## Docker resources

- [Enough Docker to be Dangerous](https://seankross.com/2017/09/17/Enough-Docker-to-be-Dangerous.html)
- [Python Docker](https://zetcode.com/python/docker/)
- [Ten simple rules for writing Dockerfiles for reproducible data science](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008316)
- [Docker info from Posit Solutions Engineering](https://solutions.posit.co/envs-pkgs/environments/docker/)

# Model metrics as metadata üéØ

## Model metrics as metadata

::: panel-tabset

### Python

```{python}
import pandas as pd
import numpy as np
from sklearn import model_selection, ensemble

housing = pd.read_parquet('../data/housing.parquet')

np.random.seed(123)
X, y = housing[["bedrooms", "bathrooms", "sqft_living", "yr_built"]], np.log10(housing["price"])
X_train, X_test, y_train, y_test = model_selection.train_test_split(
    X, y,
    test_size = 0.2
)

housing_fit = ensemble.RandomForestRegressor(n_estimators=200).fit(X, y)
```


### R

```{r}
library(tidyverse)
library(tidymodels)
library(arrow)
path <- here::here("data", "housing.parquet")
housing <- read_parquet(path)

set.seed(123)
housing_split <- housing |>
  mutate(price = log10(price)) |>
  initial_split(prop = 0.8)
housing_train <- training(housing_split)
housing_test <- testing(housing_split)

housing_fit <-
  workflow(
    price ~ bedrooms + bathrooms + sqft_living + yr_built,
    rand_forest(trees = 200, mode = "regression")
  ) |>
  fit(data = housing_train)
```


:::

## Model metrics as metadata

::: panel-tabset

### Python

```{python}
from sklearn import metrics

metric_set = [metrics.root_mean_squared_error, metrics.r2_score, metrics.mean_absolute_error]
y_predictions = pd.Series(housing_fit.predict(X_test))

housing_metrics = pd.DataFrame()

for metric in metric_set:
    metric_name = str(metric.__name__)
    metric_output = metric(y_test, y_predictions)
    housing_metrics = pd.concat(
        (
            housing_metrics,
            pd.DataFrame({"name": [metric_name],
                          "score": [metric_output]}),
        ),
        axis=0,
    )

housing_metrics.reset_index(inplace=True, drop=True)
housing_metrics
```

### R

```{r}
housing_metrics <-
    augment(housing_fit, new_data = housing_test) |>
    metrics(truth = price, estimate = .pred)

housing_metrics
```

:::

## Model metrics as metadata

::: panel-tabset

### Python

```{python}
from vetiver import VetiverModel
v = VetiverModel(
    housing_fit, 
    "seattle-housing-python", 
    prototype_data = X_train,
    metadata = housing_metrics.to_dict()
)
v.description
```


### R

```{r}
library(vetiver)
v <- vetiver_model(
    housing_fit, 
    "seattle-housing-rstats",
    metadata = list(metrics = inspect_metrics)
)
v
```

:::

## Model metrics as metadata

- We pin our vetiver model to a board to version it
- The metadata, including our metrics, are versioned along with the model

. . .

::: panel-tabset
## Python

```{python}
#| eval: false
from pins import board_connect
from vetiver import vetiver_pin_write
from dotenv import load_dotenv
load_dotenv()

board = board_connect(allow_pickle_read = True)
vetiver_pin_write(board, v)
```

```{python}
#| echo: false
#| output: false
from pins import board_temp
from vetiver import vetiver_pin_write

board = board_temp(versioned=True, allow_pickle_read=True)
vetiver_pin_write(board, v)
```


## R

```{r}
#| eval: false
library(pins)
board <- board_connect()
board |> vetiver_pin_write(v)
```

```{r}
#| echo: false
#| output: false
library(pins)
board <- board_temp(versioned = TRUE)
board |> vetiver_pin_write(v)
```

:::

## Your turn üè∫ {transition="slide-in"}

::: {.callout-note icon=false}

## Activity

Compute metrics for your model using the _testing_ data.

Store these metrics as metadata in a vetiver model object.

Write this new vetiver model object as a new version of your pin.

:::

```{r}
#| echo: false
library(countdown)
countdown(minutes = 7)
```

## Model metrics as metadata

How do we extract our metrics out to use them?

::: panel-tabset
## Python

```{python}
metadata = board.pin_meta("seattle-housing-python")
extracted_metrics = pd.DataFrame(metadata.user.get("user"))
extracted_metrics
```

## R

```{r}
extracted_metrics <- 
    board |> 
    pin_meta("seattle-housing-rstats") |> 
    pluck("user", "metrics") |> 
    as_tibble()

extracted_metrics
```

:::


## Your turn üè∫ {transition="slide-in"}

::: {.callout-note icon=false}

## Activity

Obtain the metrics metadata for your versioned model.

Optional: Redeploy your model to your Connect server, then obtain the metrics metadata for _your neighbor's_ model by calling the `/metadata` endpoint for their API.

What else might you want to store as model metadata?

How or when might you use model metadata?

:::

```{r}
#| echo: false
countdown(minutes = 7)
```

# Add a new endpoint to your API ‚ú®

## Add a new endpoint to your API

- A lot of code is being generated throughout this deployment process
- You have access to that code and can alter it yourself!
- The vetiver framework has sensible defaults but is extensible for more complex use cases
- What really sets up your model API?

## Add a new endpoint to your API

### R

```{r}
#| eval: false
vetiver_write_plumber(board, "julia.silge/seattle-housing-rstats")
```

```r
# Generated by the vetiver package; edit with care

library(pins)
library(plumber)
library(rapidoc)
library(vetiver)

# Packages needed to generate model predictions
if (FALSE) {
    library(kernlab)
    library(parsnip)
    library(recipes)
    library(workflows)
}
b <- board_connect(auth = "envvar")
v <- vetiver_pin_read(b, "julia.silge/seattle-housing-rstats", version = "78859")

#* @plumber
function(pr) {
    pr %>% vetiver_api(v)
}
```

## Add a new endpoint to your API

### Python

```{python}
#| eval: false
vetiver.write_app(board, "isabel.zimmerman/seattle-housing-python")
```

```python
from vetiver import VetiverModel
import vetiver
import pins


b = pins.board_connect(allow_pickle_read=True)
v = VetiverModel.from_pin(b, 'isabel.zimmerman/seattle-housing-python', version = '78841')

vetiver_api = vetiver.VetiverAPI(v)
api = vetiver_api.app
```


## Your turn üè∫ {transition="slide-in"}

::: {.callout-note icon=false}

## Activity

Create a Plumber or FastAPI app file to serve your model's predictions.

Run this app locally and check out the visual documentation again.

:::

```{r}
#| echo: false
countdown(minutes = 5)
```

## Add a new endpoint to your API

- In Python, you add more endpoints to your FastAPI app file
- In R, you add more endpoints in your Plumber app file
- In both cases, it is ultimately up to you to decide what your API's endpoints should be!

## Add a new endpoint to your API {auto-animate=true}

### R

```r
# Generated by the vetiver package; edit with care

library(pins)
library(plumber)
library(rapidoc)
library(vetiver)

# Packages needed to generate model predictions
if (FALSE) {
    library(kernlab)
    library(parsnip)
    library(recipes)
    library(workflows)
}
b <- board_connect(auth = "envvar")

v <- vetiver_pin_read(b, "julia.silge/seattle-housing-rstats", version = "78859")

#* @plumber
function(pr) {
    pr %>% vetiver_api(v)
}
```

## Add a new endpoint to your API {auto-animate=true}

### R

```r
# Generated by the vetiver package; edit with care

library(pins)
library(plumber)
library(rapidoc)
library(vetiver)
library(lubridate)

# Packages needed to generate model predictions
if (FALSE) {
    library(kernlab)
    library(parsnip)
    library(recipes)
    library(workflows)
}
b <- board_connect(auth = "envvar")

v <- vetiver_pin_read(b, "julia.silge/seattle-housing-rstats", version = "78859")

# todo: shap
```

## Add a new endpoint to your API {auto-animate=true}

### Python

```python
from vetiver import VetiverModel
import vetiver
import pins


b = pins.board_connect(allow_pickle_read=True)
v = VetiverModel.from_pin(b, 'isabel.zimmerman/seattle-housing-python', version = '78841')

vetiver_api = vetiver.VetiverAPI(v)
api = vetiver_api.app
```


## Add a new endpoint to your API {auto-animate=true}

### Python

```python
from vetiver import VetiverModel
import vetiver
import pins
from dotenv import load_dotenv
load_dotenv()

b = pins.board_connect(allow_pickle_read=True)
v = VetiverModel.from_pin(b, 'isabel.zimmerman/seattle-housing-python')

connect_url = "https://colorado.posit.co/rsc"
pin_path = {"shap_python": "seattle-shap-python/"}
shap_board = pins.board_url(connect_url, pin_path, allow_pickle_read = True)
explainer = shap_board.pin_read("shap_python")

def shap_explainer(data):
    import pandas as pd
    values_as_json = pd.DataFrame(explainer.shap_values(data)).to_json(orient='records')
    return values_as_json

vetiver_api = vetiver.VetiverAPI(v)
vetiver_api.vetiver_post(shap_explainer, "shap")
api = vetiver_api.app
```

## Your turn üè∫ {transition="slide-in"}

::: {.callout-note icon=false}

## Activity

Add a new endpoint to the API app file you already made.

Run the app locally and check out your new endpoint.

How might you want to use an additional endpoint?

:::

```{r}
#| echo: false
countdown(minutes = 7)
```
